{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Import Clean data\n",
    "# clean_df = pd.read_pickle(\"train_set.pkl\")\n",
    "# val_df = pd.read_pickle(\"val_set.pkl\")\n",
    "\n",
    "# Convert NumPy arrays to JSON before saving\n",
    "# clean_df['Wafer_Map'] = clean_df['Wafer_Map'].apply(lambda x: json.dumps(x.tolist()))\n",
    "# val_df['Wafer_Map'] = val_df['Wafer_Map'].apply(lambda x: json.dumps(x.tolist()))\n",
    "\n",
    "# Save to CSV\n",
    "# clean_df.to_csv(\"train_set.csv\", index=False)\n",
    "# val_df.to_csv(\"val_set.csv\", index=False)\n",
    "\n",
    "# Import Clean data\n",
    "clean_df = pd.read_csv('train_set.csv')\n",
    "val_df = pd.read_csv('val_set.csv')\n",
    "\n",
    "# For WSL2\n",
    "# data_dir = \"/mnt/c/Users/custu/My Drive/MSDS 422/M10\"\n",
    "# clean_df = pd.read_csv(f\"{data_dir}/train_set.csv\")\n",
    "# val_df = pd.read_csv(f\"{data_dir}/val_set.csv\")\n",
    "\n",
    "# Decode JSON to NumPy arrays\n",
    "clean_df['Wafer_Map'] = clean_df['Wafer_Map'].apply(lambda x: np.array(json.loads(x), dtype=np.uint8))\n",
    "val_df['Wafer_Map'] = val_df['Wafer_Map'].apply(lambda x: np.array(json.loads(x), dtype=np.uint8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 23:47:12.863952: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-02 23:47:13.409042: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-02 23:47:14.957943: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1743662835.951170   30171 gpu_device.cc:2429] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set GPU as default\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(\"Using GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743662836.483932   30171 gpu_device.cc:2429] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "I0000 00:00:1743662836.630018   30171 gpu_device.cc:2018] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13067 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5080, pci bus id: 0000:01:00.0, compute capability: 12.0\n",
      "/home/custu/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-04-02 23:47:16.969544: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_INVALID_PTX'\n",
      "\n",
      "2025-04-02 23:47:16.969585: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "\n",
      "2025-04-02 23:47:16.969595: W tensorflow/core/framework/op_kernel.cc:1843] INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "2025-04-02 23:47:16.969612: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "{{function_node __wrapped__Cast_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:Cast] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     70\u001b[39m early_stopping = EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m5\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Hyperband tuner\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m tuner = \u001b[43mkt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHyperband\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_categorical_accuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhyperband_tuning\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCNN_Model_1_v2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     81\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m tuner.search(X_train, y_train, epochs=\u001b[32m30\u001b[39m, validation_data=(X_test, y_test), callbacks=[early_stopping])\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/tuners/hyperband.py:420\u001b[39m, in \u001b[36mHyperband.__init__\u001b[39m\u001b[34m(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__init__\u001b[39m(\n\u001b[32m    394\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    395\u001b[39m     hypermodel=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    406\u001b[39m     **kwargs,\n\u001b[32m    407\u001b[39m ):\n\u001b[32m    408\u001b[39m     oracle = HyperbandOracle(\n\u001b[32m    409\u001b[39m         objective,\n\u001b[32m    410\u001b[39m         max_epochs=max_epochs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    418\u001b[39m         max_consecutive_failed_trials=max_consecutive_failed_trials,\n\u001b[32m    419\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m=\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py:122\u001b[39m, in \u001b[36mTuner.__init__\u001b[39m\u001b[34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.run_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner.run_trial:\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    116\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`hypermodel` if the user defines the search space in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    118\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    119\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musing a `HyperModel` instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    120\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43moracle\u001b[49m\u001b[43m=\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28mself\u001b[39m.max_model_size = max_model_size\n\u001b[32m    133\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer = optimizer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:132\u001b[39m, in \u001b[36mBaseTuner.__init__\u001b[39m\u001b[34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mself\u001b[39m.reload()\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_populate_initial_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# Run in distributed mode.\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dist_utils.has_chief_oracle() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dist_utils.is_chief_oracle():\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Proxies requests to the chief oracle.\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# Avoid import at the top, to avoid inconsistent protobuf versions.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:192\u001b[39m, in \u001b[36mBaseTuner._populate_initial_space\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28mself\u001b[39m.hypermodel.declare_hyperparameters(hp)\n\u001b[32m    191\u001b[39m \u001b[38;5;28mself\u001b[39m.oracle.update_space(hp)\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_activate_all_conditions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:149\u001b[39m, in \u001b[36mBaseTuner._activate_all_conditions\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m hp = \u001b[38;5;28mself\u001b[39m.oracle.get_space()\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28mself\u001b[39m.oracle.update_space(hp)\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# Update the recorded scopes.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mbuild_model\u001b[39m\u001b[34m(hp)\u001b[39m\n\u001b[32m     36\u001b[39m model = Sequential()\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# First Convolutional Block\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChoice\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconv1_filters\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m model.add(BatchNormalization())\n\u001b[32m     41\u001b[39m model.add(MaxPooling2D((\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/src/models/sequential.py:122\u001b[39m, in \u001b[36mSequential.add\u001b[39m\u001b[34m(self, layer, rebuild)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28mself\u001b[39m._layers.append(layer)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m.built = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/src/models/sequential.py:149\u001b[39m, in \u001b[36mSequential._maybe_rebuild\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    148\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].batch_shape\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33minput_shape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[32m    154\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].input_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/src/layers/layer.py:229\u001b[39m, in \u001b[36mLayer.__new__.<locals>.build_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m obj._open_name_scope():\n\u001b[32m    228\u001b[39m     obj._path = current_path()\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[32m    231\u001b[39m signature = inspect.signature(original_build_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/src/models/sequential.py:195\u001b[39m, in \u001b[36mSequential.build\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m1\u001b[39m:]:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[32m    199\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py:152\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(x, dtype, sparse, ragged)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype == \u001b[33m\"\u001b[39m\u001b[33mbool\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_int_dtype(dtype):\n\u001b[32m    148\u001b[39m         \u001b[38;5;66;03m# TensorFlow conversion is stricter than other backends, it does not\u001b[39;00m\n\u001b[32m    149\u001b[39m         \u001b[38;5;66;03m# allow ints for bools or floats for ints. We convert without dtype\u001b[39;00m\n\u001b[32m    150\u001b[39m         \u001b[38;5;66;03m# and cast instead.\u001b[39;00m\n\u001b[32m    151\u001b[39m         x = tf.convert_to_tensor(x)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.convert_to_tensor(x, dtype=dtype)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m standardize_dtype(x.dtype) == dtype:\n",
      "\u001b[31mInternalError\u001b[39m: {{function_node __wrapped__Cast_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:Cast] name: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.optimizers.schedules as schedules\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras_tuner as kt\n",
    "\n",
    "random_state = 2\n",
    "\n",
    "# Prepare data\n",
    "X_train = np.stack(clean_df['Wafer_Map'].values)  \n",
    "X_train = X_train.reshape(-1, 45, 45, 1).astype('float32')  \n",
    "X_test = np.stack(val_df['Wafer_Map'].values)  \n",
    "X_test = X_test.reshape(-1, 45, 45, 1).astype('float32') \n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = pd.factorize(clean_df['Defect_Class'])\n",
    "y_train = label_encoder[0] \n",
    "y_classes = label_encoder[1]\n",
    "y_test = val_df['Defect_Class'].map({cls: i for i, cls in enumerate(y_classes)}).fillna(-1).astype(int).values\n",
    "\n",
    "# Convert to OHE\n",
    "y_train = to_categorical(y_train, num_classes=len(y_classes))\n",
    "y_test = to_categorical(y_test, num_classes=len(y_classes))\n",
    "\n",
    "# Build model\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First Convolutional Block\n",
    "    model.add(Conv2D(filters=hp.Choice('conv1_filters', values=[16]),kernel_size=(5, 5), activation='relu', input_shape=(45, 45, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Choice('dropout1', values=[0.0]))) \n",
    "\n",
    "    # Second Convolutional Block\n",
    "    model.add(Conv2D(filters=hp.Choice('conv2_filters', values=[64]),  kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Choice('dropout2', values=[0.0])))  \n",
    "\n",
    "    # Third Convolutional Block\n",
    "    model.add(Conv2D(filters=hp.Choice('conv3_filters', values=[128]), kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(hp.Choice('dropout3', values=[0.0]))) \n",
    "\n",
    "    # Dense Layers + Output\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hp.Choice('dense_units', values=[256]),activation='relu'))\n",
    "    model.add(Dropout(hp.Choice('dropout_fc', values=[0.4]))) \n",
    "    model.add(Dense(hp.Choice('dense_units2', values=[128]),activation='relu'))\n",
    "    model.add(Dropout(hp.Choice('dropout_fc2', values=[0.4]))) \n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[0.001])),\n",
    "        loss='categorical_crossentropy',metrics=['categorical_accuracy', Precision(), Recall()])\n",
    "    return model\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Hyperband tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_categorical_accuracy',\n",
    "    max_epochs=30, \n",
    "    factor=3, \n",
    "    directory='hyperband_tuning',\n",
    "    project_name='CNN_Model_1_v2'\n",
    ")\n",
    "tuner.search(X_train, y_train, epochs=30, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "# Start time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Train\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=50, batch_size=256, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "print(f\"Training Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate\n",
    "start_time = time.time()\n",
    "eval_results = best_model.evaluate(X_test, y_test)\n",
    "end_time = time.time()\n",
    "print(f\"Evaluation Time: {end_time - start_time:.2f} seconds\")    \n",
    "print(f\"Validation Accuracy: {eval_results[1]:.4f}\")    \n",
    "print(f\"Training Accuracy: {history.history['categorical_accuracy'][-1]:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) \n",
    "y_true_classes = np.argmax(y_test, axis=1) \n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Normalize confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=y_classes, yticklabels=y_classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Normalized Confusion Matrix Custom CNN')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=y_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 41, 41, 16)        416       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 41, 41, 16)       64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 20, 20, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 20, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 18, 18, 64)        9280      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 18, 18, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 9, 9, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               295168    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 413,609\n",
      "Trainable params: 413,193\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print model\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
